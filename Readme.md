# Vision Transformer Implementation

This project implements a simplified Vision Transformer (ViT) architecture based on the paper *“An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale”* by Dosovitskiy et al. (2020). The focus is on understanding and reproducing the architecture rather than achieving optimal performance.

## Project Overview

- **Objective**: Implement the Vision Transformer architecture and test it on a subset of the CIFAR-10 dataset.
- **Dataset**: A reduced training set (20% of CIFAR-10) and the full test set.
- **Simplifications**: Reduced model complexity and training parameters to minimize resource usage.

## Requirements

- Python 3.7+
- PyTorch
- NumPy
- Matplotlib
- torchvision

## References

- [Dosovitskiy, A., et al. (2020). *An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale*](https://arxiv.org/pdf/2010.11929)